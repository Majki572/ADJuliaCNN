{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2742286\n",
      "Accuracy: 9.0\n",
      "Loss: 2.3077612\n",
      "Accuracy: 12.0\n",
      "Loss: 2.3216457\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3303354\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3969533\n",
      "Accuracy: 14.0\n",
      "Loss: 2.2974815\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3569667\n",
      "Accuracy: 11.0\n",
      "Loss: 2.3509724\n",
      "Accuracy: 8.0\n",
      "Loss: 2.3569062\n",
      "Accuracy: 8.0\n",
      "Loss: 2.3416543\n",
      "Accuracy: 16.0\n",
      "Loss: 2.2685678\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3292644\n",
      "Accuracy: 12.0\n",
      "Loss: 2.3458498\n",
      "Accuracy: 9.0\n",
      "Loss: 2.2878485\n",
      "Accuracy: 16.0\n",
      "Loss: 2.159156\n",
      "Accuracy: 10.0\n",
      "Loss: 2.3452737\n",
      "Accuracy: 8.0\n",
      "Loss: 2.2276428\n",
      "Accuracy: 10.0\n",
      "Loss: 2.3494692\n",
      "Accuracy: 6.0\n",
      "Loss: 2.2238662\n",
      "Accuracy: 7.0\n",
      "Loss: 2.3488014\n",
      "Accuracy: 6.0\n",
      "Loss: 2.3024049\n",
      "Accuracy: 8.0\n",
      "Loss: 2.3422117\n",
      "Accuracy: 8.0\n",
      "Loss: 2.358798\n",
      "Accuracy: 17.0\n",
      "Loss: 2.3100264\n",
      "Accuracy: 9.0\n",
      "Loss: 2.3211868\n",
      "Accuracy: 17.0\n",
      "Loss: 2.257124\n",
      "Accuracy: 9.0\n",
      "Loss: 2.3823173\n",
      "Accuracy: 4.0\n",
      "Loss: 2.2483325\n",
      "Accuracy: 9.0\n",
      "Loss: 2.360822\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3794365\n",
      "Accuracy: 13.0\n",
      "Loss: 2.3753507\n",
      "Accuracy: 7.0\n",
      "Loss: 2.2830715\n",
      "Accuracy: 10.0"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "include(\"ConvolutionModule.jl\")  # Load the module\n",
    "include(\"PoolingModule.jl\")  # Load the module\n",
    "include(\"FlattenModule.jl\")\n",
    "include(\"DenseModule.jl\")\n",
    "\n",
    "include(\"MNISTDataLoader.jl\")\n",
    "include(\"LossAndAccuracy.jl\")\n",
    "include(\"NetworkHandlers.jl\")\n",
    "\n",
    "using .ConvolutionModule, .PoolingModule, .MNISTDataLoader, .FlattenModule, .DenseModule \n",
    "\n",
    "# Load and preprocess the data\n",
    "train_features, train_labels = MNISTDataLoader.load_data(:train)\n",
    "train_x, train_y = MNISTDataLoader.preprocess_data(train_features, train_labels; one_hot=true)\n",
    "\n",
    "# Create batches\n",
    "batch_size = 100  # Define your desired batch size\n",
    "train_data = MNISTDataLoader.batch_data((train_x, train_y), batch_size; shuffle=true)\n",
    "# input_image = Float64.(input_image)\n",
    "\n",
    "# Initialize layers\n",
    "conv_layer1 = ConvolutionModule.init_conv_layer(3, 3, 1, 6, 1, 0)\n",
    "pool_layer1 = PoolingModule.init_pool_layer(2, 2, 2)\n",
    "conv_layer2 = ConvolutionModule.init_conv_layer(3, 3, 6, 16, 1, 0)\n",
    "pool_layer2 = PoolingModule.init_pool_layer(2, 2, 2)\n",
    "flatten_layer = FlattenModule.FlattenLayer()\n",
    "dense_layer1 = DenseModule.init_dense_layer(400, 84, DenseModule.relu, DenseModule.relu_grad)  # Adjusted to correct input size\n",
    "dense_layer2 = DenseModule.init_dense_layer(84, 10, DenseModule.identity, DenseModule.identity_grad)\n",
    "\n",
    "# Workaround because of namespaces...\n",
    "function backward_pass_master(network, grad_loss, transition_output_pool=nothing)\n",
    "    for layer in reverse(network)\n",
    "        if isa(layer, ConvolutionModule.ConvLayer)\n",
    "            grad_loss = ConvolutionModule.backward_pass(layer, grad_loss)\n",
    "\n",
    "        elseif isa(layer, PoolingModule.MaxPoolLayer)\n",
    "            grad_loss = PoolingModule.backward_pass(layer, grad_loss)\n",
    "\n",
    "        elseif isa(layer, DenseModule.DenseLayer)\n",
    "            grad_loss = DenseModule.backward_pass(layer, grad_loss)\n",
    "\n",
    "        elseif isa(layer, FlattenModule.FlattenLayer)\n",
    "            grad_loss = FlattenModule.backward_pass(layer, grad_loss)\n",
    "        else\n",
    "            println(\"No backward pass defined for layer type $(typeof(layer))\")\n",
    "        end\n",
    "    end\n",
    "    return grad_loss\n",
    "end\n",
    "\n",
    "\n",
    "# Assemble the network\n",
    "network = (conv_layer1, pool_layer1, conv_layer2, pool_layer2, flatten_layer, dense_layer1, dense_layer2)\n",
    "\n",
    "using .NetworkHandlers, .LossAndAccuracy\n",
    "function train_epoch(network, inputs, targets, epochs)\n",
    "    for epoch in 1:epochs\n",
    "        accumulated_accuracy_epoch = 0.0\n",
    "        accumulated_accuracy_batch = 0.0\n",
    "        for i in 1:size(inputs, 4)  # Iterate over each example\n",
    "            input = inputs[:, :, :, i]\n",
    "            target = targets[:, i]\n",
    "            \n",
    "            # Forward pass\n",
    "            output = NetworkHandlers.forward_pass_master(network, input)\n",
    "            \n",
    "            # Calculate loss, accuracy, and its gradient\n",
    "            loss, accuracy, grad_loss = LossAndAccuracy.loss_and_accuracy(output, target)\n",
    "            accumulated_accuracy_epoch += accuracy\n",
    "            accumulated_accuracy_batch += accuracy\n",
    "            \n",
    "            if(i % 100 == 0)\n",
    "                println(\"Loss: \", loss)\n",
    "                println(\"Accuracy: \", round(accumulated_accuracy_batch / 100, digits=2))\n",
    "                accumulated_accuracy_batch = 0.0\n",
    "            end\n",
    "\n",
    "            # Backward pass\n",
    "            backward_pass_master(network, grad_loss)\n",
    "        end\n",
    "        println(\"Epoch $(epoch) done\")\n",
    "        println(\"Accuracy: \", round(accumulated_accuracy_epoch / size(inputs, 4), digits=2))\n",
    "        accumulated_accuracy_epoch = 0.0\n",
    "    end\n",
    "end\n",
    "\n",
    "train_epoch(network, train_x, train_y, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
