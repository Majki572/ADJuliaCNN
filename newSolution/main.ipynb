{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions after layer Main.ConvolutionModule.ConvLayer: (26, 26, 6)\n",
      "Output dimensions after layer MaxPoolLayer: (13, 13, 6)\n",
      "Output dimensions after layer Main.ConvolutionModule.ConvLayer: (11, 11, 16)\n",
      "Output dimensions after layer MaxPoolLayer: (5, 5, 16)\n",
      "Output dimensions after layer FlattenLayer: (400, 1)\n",
      "Output dimensions after layer DenseLayer: (84, 1)\n",
      "Output dimensions after layer DenseLayer: (10, 1)\n",
      "Loss at iteration 1: 2.3026009\n",
      "Type of network before backward pass: Tuple{Main.ConvolutionModule.ConvLayer, MaxPoolLayer, Main.ConvolutionModule.ConvLayer, MaxPoolLayer, FlattenLayer, DenseLayer, DenseLayer}\n",
      "doing layer DenseLayer(Float32[-0.00979371 -0.00076838006 0.0021892902 -0.005673719 0.00619282 -0.00916964 0.0042065023 0.010305134 0.012667057 -0.010908055 0.006743393 0.0003324397 -0.010962147 -0.005868128 -0.0072961724 0.010630407 0.017568689 -0.013721497 -0.0059507326 0.0029956384 -0.0036387544 -0.0073196474 -0.0083547365 -0.0071967705 0.012549233 0.010965715 0.0071091787 0.0017542692 -0.0029721155 0.011949812 0.021197094 0.010147469 0.0027229064 -0.025677456 -0.00060021214 0.01657209 0.0012879935 0.004500723 -0.0024395748 -0.0061272443 -0.008333996 0.014521071 -0.003432123 0.008837217 -0.010216034 -0.0020103392 0.0028071117 -0.0007373652 -0.0056963884 -0.010551389 -0.0038845763 0.013143192 -0.0074521056 0.016794467 0.0028329995 -0.0031937694 -0.012601062 0.008140835 -0.014537973 -0.0030895954 0.008361733 -0.007781817 0.0026632627 -0.017141124 -0.0074533825 0.002529818 0.005195115 0.0026735219 0.01630098 -0.008996379 0.015585202 0.013694089 0.0025809165 0.005917612 -0.0072259945 -0.0072456906 -0.009115824 -0.00282236 0.008339237 0.0042546154 0.0033205666 0.0051421695 0.008194604 -0.0063240086; -0.008244753 0.011877342 0.021294976 0.004953396 -0.0073865387 0.019207884 0.011844074 0.0073327697 0.0131952185 0.005270901 0.009644347 0.014515444 -0.006748196 0.008581932 0.0068760864 0.0010568473 -0.0020619312 0.01754062 0.0070405523 0.0026581683 0.013274069 0.0099871745 -0.008794997 0.005136707 -0.004630637 -0.003907446 0.0013513545 -0.015562554 -0.008156575 -0.0011994739 -0.00095875334 -0.004034728 -0.0049340837 -0.00047613736 0.0019939411 -0.010294481 0.019122059 0.012442167 0.0017240292 0.015695877 -0.0043703313 -0.013909763 0.021068132 -0.011216923 0.0124784075 0.0062780688 -0.006307352 0.01037877 0.007687872 0.0052222265 -0.008458933 0.007985711 -3.4303688f-5 -0.005362373 0.011324322 -0.00043990932 0.008870516 0.008514398 0.020387914 0.0011949715 0.00048557395 -0.013515236 -0.011215508 -0.0049768835 -0.011068072 -0.0001518711 -0.012114388 -0.0038700427 -0.004325055 -0.0072621116 0.0030592852 -0.0021217747 -0.00783038 -0.0011627555 0.011562068 -0.0028535759 0.004904593 0.0083863055 -0.007013206 0.0020821237 -0.005580423 0.014649329 -0.00501891 -0.004035988; 0.0052739405 0.00441226 -0.005027818 0.005648914 0.014429607 -0.017988876 0.010297458 0.005258672 -0.0095233675 0.0064066765 0.00061632955 0.0009895609 0.015473594 -0.02669047 0.002565668 0.0026903125 0.013499454 0.013354039 -0.00010402096 0.0066167573 -0.006616995 0.008496264 0.01765073 0.0013950547 -0.0011286411 -0.017562542 -0.004699228 0.00044368423 -0.0051334435 -0.009029485 -0.0127311135 0.016499335 -0.0042938185 -0.011791741 -0.015272309 0.01746906 -0.010322479 0.007456209 0.0022187983 -0.0051844805 0.0066083805 -0.004083166 0.003651237 0.018258603 0.0043307906 -0.009543672 0.005642774 -0.0046647927 8.9718545f-5 -0.0034712555 0.0044970163 -0.01134624 0.00410283 0.0040662596 -0.0005715405 0.0052639777 -0.00037966899 -0.008383531 0.0051338035 0.015452274 0.015142702 -0.0031380926 -0.0032909827 7.974095f-5 -0.009230007 0.012077176 0.017930144 0.0034405792 -0.002448764 -0.01667175 -0.019766483 -0.002012314 0.00011447923 -0.004501434 -8.346497f-5 0.0076205307 -0.019033207 0.0055919513 0.008140064 0.0077763377 0.009399849 -0.0058428 0.0015807077 0.0024025466; 0.00588787 -0.0037793806 0.021024507 0.011404438 0.003379429 0.015322962 0.017333612 -0.013169418 -0.010257351 -0.018101087 0.0018664253 -0.0035041177 0.009290033 0.0076377937 -0.0057040476 0.007609221 0.008474976 -0.0007099923 -0.0036459272 -0.013931871 0.0070151864 -0.0054485747 -0.016813263 -0.0044738785 -0.017668543 0.010460521 0.007289137 0.014788124 -0.0010690467 2.9556979f-5 0.00087887817 0.0026076925 -0.004324717 -0.0071061086 -0.003962641 0.0075195394 -0.0035535991 -0.009542066 -0.0051472504 0.0031708665 0.007304211 -0.011523098 -0.013868511 -0.017018229 -0.00018878364 -0.0007843792 -0.0018713692 0.011328985 -0.014158111 -0.016760081 0.0009961872 0.0024713485 -0.017988289 0.0038731052 -0.0011916142 -0.008068953 0.010735343 -0.00911481 0.010754717 0.0053068656 -0.0021195281 0.0217384 -0.0095664365 0.008204375 0.0071640084 0.010175029 0.004718269 0.006450052 0.0016473215 -0.026609117 0.012401702 -0.012665208 0.0103315 0.0030702516 0.0034179904 -0.013969784 -0.0014578915 -0.0022456183 -0.006719439 -0.027471967 -0.010260851 0.016765473 0.011367323 0.0074334107; -0.0062954756 0.009616385 0.0031024064 -0.0021580833 -0.00020358758 0.006994148 0.016463252 -0.017941244 -0.010196997 9.98015f-5 -0.021509238 -0.0029812302 -0.015987622 0.0033393565 0.001968331 0.015769076 -0.014060759 0.008483878 -0.017389407 -0.010949594 -0.0010158588 0.0028171833 0.0049257334 0.012852809 0.011833482 0.0053588897 -0.011877166 0.0011721127 -0.0018653114 -0.0026980962 -0.012262508 0.01712981 -0.014674838 -0.004041305 -0.020553553 0.0015317068 -0.028381096 -0.0072449786 -0.0055316347 -0.005195701 -0.0066624954 0.00019375462 -0.0030286966 0.012934436 0.010058408 0.0010358936 -0.028943483 -0.0017286518 0.012201305 0.00022344598 0.002880988 0.0033651902 -0.0063326266 0.011507507 0.00051214395 0.0073087066 -0.010823824 0.008617012 0.0040840073 0.0038822244 -0.012273393 0.0013323261 -0.0045083812 -0.003125657 0.007761979 0.00869332 0.018257583 0.0052533 -0.0033356296 0.0015251411 -0.018625688 0.008373298 0.012340127 -0.015526203 -0.0022917027 0.009422822 0.01746525 0.008845245 0.019972071 0.010159574 -0.0074764616 -0.005713057 -0.009220744 -0.017549304; 0.0050289165 -0.00025541495 0.013383684 -0.013344527 0.013985906 0.01844043 0.015719077 -0.0061447755 0.004101756 0.007541274 0.009341804 -0.009903974 0.008903057 -0.010223917 -0.00036711778 -0.00029600505 0.012954079 -0.00015269213 -0.01463826 0.00024752034 -0.002542945 -0.0137385605 -0.0008129021 0.010592288 -0.01338967 -0.00039487812 -0.0005733733 -0.00462212 -0.021588506 -0.011136796 0.01702662 0.008612229 0.009166282 -0.0008447278 0.00094314374 0.01041555 0.0009377325 0.0049390676 -0.013270206 -0.004264465 0.00088743225 -0.012259581 -0.014502896 -0.008039857 -0.015696196 0.0031572739 0.0033090618 -0.013314392 0.006240642 -0.001997561 0.001351222 -0.009751237 0.0016902431 0.0035677026 -0.004163368 0.016389238 0.0051574185 0.005573458 0.004922852 0.0124030365 -0.0048115337 0.01095391 0.00030404475 -0.0018220287 0.006461337 -0.01531218 -0.0025589496 -0.0063138315 -0.012979226 -0.013723868 0.0046085054 -0.022129001 -0.0067891064 0.020628387 -0.010025553 -0.017160727 -0.0018570634 -0.006753482 -0.011001455 -0.0044821403 0.0022134928 0.0063535366 0.006586307 0.012181921; -0.012583444 0.011391692 -0.0046652956 0.012492652 -0.01723129 -0.013070287 -0.0011503258 0.007106858 0.0037039616 0.0064724484 -0.016758407 -0.0137550635 -0.000496868 0.008645033 -0.013060059 -0.0041455296 0.012159605 0.016115574 -0.02319974 -0.0005705788 0.008801272 -0.0013135938 0.006002248 -0.0069909142 -0.025555486 0.0003349647 0.008317916 -0.0017860789 -0.014122368 0.0036103418 0.003294681 -0.008389257 0.016621046 0.009212336 0.011404123 -0.018246604 0.005148177 0.017827919 0.0013267488 0.0012762629 -0.006775297 -0.0018985379 -0.020374374 0.012182766 0.012378805 0.008178345 0.0050294423 -0.0359718 0.008590385 -0.001097388 -0.003826922 0.012263964 -0.005107506 -0.0065795532 0.0017035931 0.005532249 -0.01166021 -0.003668366 0.0022701966 -0.011899438 0.013064509 0.006691392 -0.013250777 -0.021535438 -0.011251973 -0.015050809 -0.015298909 0.0011834912 -0.0015744551 0.0016190279 0.00805051 -0.0069004325 -0.0020699857 -0.0129666 0.010230176 0.0007093794 0.007643467 0.009051846 0.01429854 0.0016624726 -0.003493922 0.00990406 0.008764025 -0.008625061; 0.020934023 0.0017164048 0.0069063418 0.004349161 -0.012494353 -0.004208239 -0.01426591 0.012193007 -0.023631498 -0.013999753 0.008413544 0.018356008 0.0126551455 -0.005846916 -0.008131213 5.7913134f-5 -0.008343838 -0.012379622 0.035437614 0.0016852719 -0.0041178465 0.0043180846 -0.005988233 -0.0028679739 0.008928079 0.014874464 -0.008978759 -0.0041112793 -0.005620723 -0.019927701 0.0057159304 0.0039745355 0.002718006 -0.0020520275 0.0010485911 -0.017708106 0.0053758044 0.0024575475 0.0027198528 -0.011072331 -0.011798667 0.005356832 0.0014418584 0.008942465 0.004086457 0.008351834 0.007964656 -0.0099580735 -0.0067793173 0.00023871455 -0.007746362 0.0067520672 -0.007505088 -0.0027734125 -0.006250495 -0.0034786477 0.0052996827 -0.0038464123 -0.0023832517 0.007502897 0.004372934 0.005627759 0.004897477 0.010390777 0.0005060663 -0.008185833 -0.003036988 0.0046935445 0.0010508645 -0.004048133 -0.023682496 -0.015863169 -0.021782707 -0.0071651177 0.018402258 -0.017179566 -0.0070298016 -0.0022664918 -0.006753833 -0.005552082 0.012318229 0.014737924 0.0028319894 0.0026473159; -0.010177285 0.011099288 -0.016244603 0.009960981 0.005229975 0.006302735 -0.013175626 0.007749782 0.008344061 0.010612281 0.010495678 -0.0036183642 -0.0094036255 -0.0151938945 0.005992009 -0.0034318622 0.0037418536 -0.0049387277 0.002616281 0.0055663926 -0.00063700916 0.0007597507 0.009170024 -0.018598672 0.0060036797 0.011734099 -0.023250261 0.0106410915 0.014077988 -0.013911875 0.0020345363 -0.0042449385 -0.008110967 0.019994726 0.011728862 -0.010683742 0.02105674 -0.0034957258 0.010981718 0.011133714 0.011279963 -0.008687278 -0.014181274 -0.016274277 0.0061657047 -0.0064912415 -0.011681144 0.017410817 -0.01697894 0.012733529 0.0029538136 0.0036278437 -0.016109193 2.4803827f-5 0.0060587437 0.010046312 0.003171063 -0.0067595085 0.00036987895 0.008691093 -0.012297932 -0.0017455665 -0.008626451 0.01595575 -0.0016217562 -0.0071907244 -0.008995035 -0.010632917 -0.0024583617 -0.008523801 -0.006865366 -0.020655414 -0.0075082844 -0.0065273503 0.012288772 -0.0017284512 -0.0051262868 0.0030365603 0.005203644 -0.01304063 -0.00023501801 0.0053042085 -0.01872677 -0.010334523; -0.0040473486 -0.0061935037 -0.0056133126 -0.00026915636 -0.012808984 0.007907427 0.018124534 -0.0074490467 0.024134895 0.0020542634 -0.021227105 -0.0003014925 0.0015433314 0.00013871449 5.222332f-6 0.0037738685 -0.0035155707 -0.0002842644 0.0060687307 0.0027365994 -0.008066989 0.0023865018 -0.008109665 -0.0015709072 -0.015885817 -0.015001863 0.0031389196 -0.012302173 -0.0019090376 0.0022675346 0.0038895982 -0.0069994293 0.013902318 -0.0007224175 -0.0023761995 -0.0037201073 -0.010899723 0.0038566266 0.00376394 0.003123309 0.0074493214 0.024012128 -0.0015374381 0.0067796246 -0.008905941 -0.0029609178 -0.0042764586 -0.0031587346 -0.012777096 0.003407656 -0.015483464 -0.02172822 -0.0046840305 -0.0032079332 0.005333199 -0.0007324292 0.0042146784 0.022763604 0.0011026731 -0.013952237 0.0034808773 -0.012527298 -0.010281669 0.0044054547 -0.0060809883 -0.008190918 0.010715026 -0.0027171837 -0.005927685 0.0010110866 -0.0015329646 0.007386249 0.013010681 -0.0044591874 -0.0063919453 -0.007117099 0.002395995 -0.009595211 0.007996839 0.005809644 -0.0002794199 -0.010189755 0.015098756 0.005986684], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Main.DenseModule.identity, Main.DenseModule.identity_grad, Float32[-7.3698566f-6; 3.7269806f-6; 7.872514f-6; -1.7196191f-5; 2.8579087f-5; -1.8265848f-5; 8.599367f-6; 3.30364f-7; -2.3497705f-5; -7.2793446f-6;;], Float32[0.00010892942; 0.00031224795; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 8.724767f-5; 0.0; 0.0; 0.0; 0.00014072105; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 8.9544905f-5; 0.00032348165; 0.00031547347; 0.00029634294; 0.00019846544; 0.0; 4.599201f-5; 0.0; 0.0; 0.0; 0.0; 0.0; 0.0; 0.00013457044; 0.0; 0.00011202981; 3.6025053f-6; 8.717008f-5; 0.0; 0.0; 2.1908167f-5; 0.0; 0.0; 0.00035475206; 0.00026591477; 0.00034683998; 0.0; 0.0; 8.312932f-5; 0.0; 6.93521f-7; 0.0; 0.0; 0.0002937428; 0.0; 0.0; 0.00028428598; 0.00010373146; 7.6809156f-5; 1.6308713f-5; 0.0002465069; 0.0003753257; 0.0; 0.0; 0.00013489506; 0.0; 0.00016821879; 0.0; 0.0; 0.00032496414; 0.0; 0.0004593427; 0.00013065225; 0.0; 0.00015652186; 0.0; 0.00011629895; 0.0; 2.2960032f-5; 0.0; 0.0; 0.00014716122; 0.0; 0.0;;])\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `backward_pass` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `backward_pass` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] backward_pass_master(network::Tuple{Main.ConvolutionModule.ConvLayer, MaxPoolLayer, Main.ConvolutionModule.ConvLayer, MaxPoolLayer, FlattenLayer, DenseLayer, DenseLayer}, grad_loss::Float64)\n",
      "   @ Main.NetworkHandlers f:\\GitHubRepository\\ADJuliaCNN\\ADJuliaCNN\\newSolution\\NetworkHandlers.jl:18\n",
      " [2] train_epoch(network::Tuple{Main.ConvolutionModule.ConvLayer, MaxPoolLayer, Main.ConvolutionModule.ConvLayer, MaxPoolLayer, FlattenLayer, DenseLayer, DenseLayer}, inputs::Array{Float32, 4}, targets::Matrix{Int64}, epochs::Int64)\n",
      "   @ Main f:\\GitHubRepository\\ADJuliaCNN\\ADJuliaCNN\\newSolution\\main.ipynb:49\n",
      " [3] top-level scope\n",
      "   @ f:\\GitHubRepository\\ADJuliaCNN\\ADJuliaCNN\\newSolution\\main.ipynb:54"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "include(\"ConvolutionModule.jl\")  # Load the module\n",
    "include(\"PoolingModule.jl\")  # Load the module\n",
    "include(\"FlattenModule.jl\")\n",
    "include(\"DenseModule.jl\")\n",
    "\n",
    "include(\"MNISTDataLoader.jl\")\n",
    "include(\"LossAndAccuracy.jl\")\n",
    "include(\"NetworkHandlers.jl\")\n",
    "\n",
    "using .ConvolutionModule, .PoolingModule, .MNISTDataLoader, .FlattenModule, .DenseModule # Use the namespace\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_features, train_labels = MNISTDataLoader.load_data(:train)\n",
    "train_x, train_y = MNISTDataLoader.preprocess_data(train_features, train_labels; one_hot=true)\n",
    "\n",
    "# Create batches\n",
    "batch_size = 100  # Define your desired batch size\n",
    "train_data = MNISTDataLoader.batch_data((train_x, train_y), batch_size; shuffle=true)\n",
    "# input_image = Float64.(input_image)\n",
    "\n",
    "# Initialize layers\n",
    "conv_layer1 = ConvolutionModule.init_conv_layer(3, 3, 1, 6, 1, 0)\n",
    "pool_layer1 = PoolingModule.init_pool_layer(2, 2, 2)\n",
    "conv_layer2 = ConvolutionModule.init_conv_layer(3, 3, 6, 16, 1, 0)\n",
    "pool_layer2 = PoolingModule.init_pool_layer(2, 2, 2)\n",
    "flatten_layer = FlattenModule.FlattenLayer()\n",
    "dense_layer1 = DenseModule.init_dense_layer(400, 84, DenseModule.relu, DenseModule.relu_grad)  # Adjusted to correct input size\n",
    "dense_layer2 = DenseModule.init_dense_layer(84, 10, DenseModule.identity, DenseModule.identity_grad)\n",
    "\n",
    "# Assemble the network\n",
    "network = (conv_layer1, pool_layer1, conv_layer2, pool_layer2, flatten_layer, dense_layer1, dense_layer2)\n",
    "\n",
    "using .NetworkHandlers, .LossAndAccuracy\n",
    "function train_epoch(network, inputs, targets, epochs)\n",
    "    for epoch in 1:epochs\n",
    "        for i in 1:size(inputs, 4)  # Iterate over each example\n",
    "            input = inputs[:, :, :, i]\n",
    "            target = targets[:, i]\n",
    "            \n",
    "            # Forward pass\n",
    "            output = NetworkHandlers.forward_pass_master(network, input)\n",
    "\n",
    "            # Calculate loss and its gradient\n",
    "            loss, grad_loss = LossAndAccuracy.loss_and_accuracy(output, target)\n",
    "            println(\"Loss at iteration $i: $loss\")\n",
    "\n",
    "            # Backward pass\n",
    "            NetworkHandlers.backward_pass_master(network, grad_loss)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "train_epoch(network, train_x, train_y, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
